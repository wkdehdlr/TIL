# 가상 면접 사례로 배우는 대규모 시스템 설계 기초

## 1장. 사용자 수에 따른 규모 확장성
### 어떤 데이터베이스를 사용할 것인가?
- 비 관계형 데이터 베이스가 나은 경우
    - 아주 낮은 응답 지연시간
    - 다루는 데이터가 비정형
    - 데이터(json, yaml, xml 등)를 직렬화하거나 역직렬화 할 수 있기만 하면 됨
    - 아주 많은 양의 데이터 저장 필요
### 수직적 규모 확장 vs 수평적 규모 확장
- 스케일 업
    - 서버에 고사양 자원을 추가
    - 단점
        - 한 대의 서버에 자원을 무한대로 증설할 방법은 없다
        - 자동복구 방안이나 다중화 방안이 없다
- 스케일 아웃
    - 더 많은 서버를 추가
### 로드밸랜서
- 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산
### 데이터베이스 다중화
- 원본은 `주 서버(master)`에, 사본은 `부 서버(slave)`에 저장
- 쓰기 연산은 마스터만 지원
- 주 주서버 다운 시 -> `다중 마스터`나 `원형 다중화` 검토
### 캐시
- 응답시간은 `캐시`와 `CDN`을 통해 개선할 수 있다
- 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리에 저장
- 갱신은 자주 일어나지 않지만 참조는 빈번한 경우 적합
- 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않으면 일관성이 깨짐
- 캐시 데이터 방출 정책, LRU, FIFO 등등
### CDN
- 정적 콘텐츠를 전송하는데 쓰임
- 고려사항
    - 자주 사용되는 콘텐츠를 캐싱
    - 적절한 만료 시한 설정
      - 너무 길면 일관성이 떨어짐
      - 너무 짧으면 원본 서버에 빈번히 접속
    - CDN 장애 대처 방안
    - 콘텐츠 무효화
      - 아직 캐싱이 유효한 콘텐츠라 하더라도 CDN에서 갱신할 필요가 있음
      - 오브젝트 버저닝 ex> image.png?20220328
### 무상태(stateless) 웹 계층
- 수평 확장을 위해서 상태 정보(사용자 세션 데이터 등)를 웹 계층에서 제거해야함
- 로드밸랜서에서 고정 세션(sticky session)을 지원하긴 하지만 부담이 많음
### 데이터 센터
- 트래픽 우회
- 데이터 동기화
### 로그, 메트릭 그리고 자동화
### 데이터베이스의 규모 확장
- 수평적 확장(`샤딩`)
    - 데이터의 재 샤딩
    - 유명인사문제
        - 유명인사가 전부 같은 샤드에 할당된다면 해당 샤드에 과부하 발생
        - 유명인사 각각에 샤드 하나씩 할당하거나, 더 잘개 쪼개거나
    - 조인과 비정규화
        - 하나의 DB를 여러 샤드로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들다
        - 하나의 테이블에서 질의가 수행되도록 DB 비정규화
### 백만 사용자, 그리고 그 이상
![확장성](https://user-images.githubusercontent.com/26949623/161415978-779f9b64-4f1a-4902-8b92-82329072228e.png)
- 웹 계층은 무상태 계층으로
- 모든 계층에 대한 다중화 도입
- 가능한 한 많은 데이터를 캐시
- 여러 데이터 센터를 지원
- 정적 콘텐츠는 CDN
- 데이터 계층은 샤딩을 통해 규모를 확장
- 각 계층은 독립적 서비스로 분할
- 모니터링 구축
## 4장. 처리율 제한 장치의 설계
### 처리율 제한 알고리즘
- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터
### 토큰 버킷
![토큰 버킷](https://user-images.githubusercontent.com/26949623/161415308-fb5052ad-b33b-4fd4-a8de-e6c1a68c4a93.png)
![토큰 버킷2](https://user-images.githubusercontent.com/26949623/161415310-4ee2ca44-7f40-41c3-ab05-bff41fd235c6.png)
- 토큰 버킷은 지정된 용량을 갖는 컨테이너
- 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다
- 토큰이 꽉 찬 버킷에는 더 이상의 토큰은 버려진다
- 토큰 공급기는 버킷에 매초 2개의 토큰을 추가
- 각 요청은 처리될 때마다 하나의 토큰을 사용
- 적절한 버킷 수?
    - API 엔드포인트마다
    - IP 마다
    - 모든 요청을 하나의 버킷으로
### 누출 버킷
![누출 버킷](https://user-images.githubusercontent.com/26949623/161415311-354358b2-d19c-4fa0-8569-3e7b4fc3c767.png)
- FIFO
- 요청이 도착하면 큐에 쌓는다(큐가 가득 차 있으면 해당 요청은 버린다)
- 지정된 시간마다 큐에서 요청을 꺼내 처리
### 고정 윈도 카운터
![고정 윈도 카운터](https://user-images.githubusercontent.com/26949623/161415305-b2d29a10-a27b-4ec2-8c02-88655a8fa084.png)
- 타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 설정
- 요청이 접수될 때마다 카운터 1 증가
- 카운터가 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버림
- 윈도의 경계 부근에 순간적으로 많은 트래픽이 몰리면 할당된 양보다 더 많은 요청이 처리될 수 있다
### 이동 윈도 로그
![이동 윈도 로그](https://user-images.githubusercontent.com/26949623/161415313-b856ba97-ef81-44bd-ace6-e12ca16a16a7.png)
- 요청의 타임스탬프를 추적
- 보통 레디스의 정렬 집함 같은 캐시에 보관
- 새 요청이 오면 만료된 타임스탬프 제거
### 이동 윈도 카운터
![이동 윈도 카운터](https://user-images.githubusercontent.com/26949623/161415315-098fdffe-0313-40cc-aa2a-a898521682a9.png)

### 분산 환경에서의 처리율 제한 장치의 구현
- 경쟁 조건
    - 루아 스크립트
    - 정렬 집합
- 동기화
    - 중앙 집중형 데이터 저장소 사용 : 레디스
### 처리율 제한을 회피하는 방법
- 클라이언트 측 캐시를 이용해 API 호출 횟수를 감소
- 클라이언트가 예외적 상황으로부터 우아하게(gracefully) 복구될 수 있도록
- 재시도 로직을 구현할 때는 충분한 백오프 시간을 둔다
- 다양한 계층에서의 처리율 제한
    - Iptables를 사용하면 OSI 중 네트워크계층에서 처리율 제한 가능